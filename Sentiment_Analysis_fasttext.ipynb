{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ5SE1D2mFMs"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PAG915JevD3i"
   },
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "import random\n",
    "import torch\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random_state = random.seed(SEED)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:1\" if \n",
    "    torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm') # <1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "\n",
    "torch.cuda.set_device(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AEjFcr_aJgIr"
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_iter, test_iter = IMDB(\n",
    "    split=('train', 'test')) #<1>\n",
    "\n",
    "train_dataset = list(train_iter) #<2>\n",
    "test_dataset  = list(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.70)\n",
    "train_data, valid_data = \\\n",
    "    random_split(train_dataset, \n",
    "        [num_train, \n",
    "         len(train_dataset) - num_train]) # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1615841915453,
     "user": {
      "displayName": "Joe Papa",
      "photoUrl": "",
      "userId": "00487850786587503652"
     },
     "user_tz": 240
    },
    "id": "7IOq1ufhq01Q",
    "outputId": "ffa9f08a-66ac-4119-a257-c4fd2c035ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500 7500 25000\n",
      "neg\n",
      "I missed the beginning but I did see most of it. A friend got it on DVD in the cheap room at FYE.<br /><br />The skits are all very short, and yet most of them are still too long. The majority of them, they seem to have forgotten to have something funny! Quite a lot of racist/sexist/\"homophobic\" humor in it, skits based on stereotypes, or skits which use racist terms for people.<br /><br />I'm trying to remember anything I thought was funny in it, and I'm having trouble.... The logo for the Tunnel Vision network is a lipsticked mouth with an eyeball in it. The mouth opens and closes over the eye like eyelids. Kind of creepy.<br /><br />What a disappointment. Most of the actors went on to better things, and it's lucky this bomb didn't hold them back.\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data), len(test_dataset))\n",
    "# out:17500 7500 25000\n",
    "\n",
    "data_index = 21\n",
    "print(train_data[data_index][0])\n",
    "# out: (your results may vary)\n",
    "#   pos\n",
    "\n",
    "print(train_data[data_index][1])\n",
    "# out: (your results may vary)\n",
    "# ['This', 'film', 'moved', 'me', 'beyond', 'comprehension', ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embed_len = 200\n",
    "global_vectors = GloVe(name='6B', dim=embed_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2661,  0.2182, -0.1100,  ..., -0.1198, -0.1916, -0.1352],\n",
       "        [ 0.1765,  0.2921, -0.0021,  ..., -0.2077, -0.2319, -0.1081],\n",
       "        [ 0.1815,  0.2663,  0.0550,  ...,  0.5375,  0.3151,  0.0162],\n",
       "        [ 0.0367,  0.1989, -0.0930,  ..., -0.0133, -0.0039,  0.7128],\n",
       "        [ 0.8540,  0.5715, -0.0237,  ...,  0.3108, -0.2230,  0.2037],\n",
       "        [ 0.3911,  0.4019, -0.1505,  ..., -0.0348,  0.0798,  0.5031]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = global_vectors.get_vecs_by_tokens(tokenizer(\"Hello, How are you?\"), lower_case_backup=True)\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vectors.get_vecs_by_tokens(\"<BOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239778,
     "status": "ok",
     "timestamp": 1615842157475,
     "user": {
      "displayName": "Joe Papa",
      "photoUrl": "",
      "userId": "00487850786587503652"
     },
     "user_tz": 240
    },
    "id": "Sc9_0aaBODCh",
    "outputId": "85e18e96-9ec4-42fa-fe04-478d5e10a886"
   },
   "outputs": [],
   "source": [
    "# this is using the frequencies in the data \n",
    "\n",
    "# https://coderzcolumn.com/tutorials/artificial-intelligence/how-to-use-glove-embeddings-with-pytorch#Load-Glove-'42B'-Embeddings\n",
    "\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    " \n",
    "# tokenizer(next(train_iter)[1])\n",
    "\n",
    "# create vocabulatory\n",
    "counter = Counter()\n",
    "for (label, line) in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "# be careful, lower case vocab to call function   \n",
    "vocab = vocab(counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
    "vocab.set_default_index(vocab['<unk>'])  # default index for oov words\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23404, 'was', 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), vocab.lookup_token(21), vocab['was']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up embedding for the vocabulatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding for dat\n",
    "\n",
    "# embed_len = 100\n",
    "\n",
    "glove_embedding_tensor = torch.zeros(len(vocab),  embed_len).to(device)\n",
    " \n",
    "glove_embedding_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(vocab)):\n",
    "    try: \n",
    "        glove_embedding_tensor[i] = global_vectors.get_vecs_by_tokens(vocab.lookup_token(i))\n",
    "    #except KeyError as e:\n",
    "    #    glove_embedding_tensor[i] = torch.normal(0, 1, size=(embed_len,))\n",
    "    except KeyError:\n",
    "        glove_embedding_tensor[i] = torch.normal(0, 1, size=(embed_len,))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23404, 200]),\n",
       " tensor([[ 4.7241e-01,  1.3480e-01, -3.0800e-01, -3.8037e-01, -5.0223e-02,\n",
       "          -1.7769e-01, -6.5435e-01,  7.7492e-02,  5.4810e-01,  4.0445e-01,\n",
       "          -2.0210e-01,  5.2530e-01,  2.4836e-01, -1.8132e-01,  5.5969e-02,\n",
       "           6.9195e-02, -5.0195e-02,  4.9772e-01,  1.6974e-01, -2.0894e-01,\n",
       "           1.6659e-01,  2.4535e+00, -1.7690e-01,  1.8831e-01,  2.0600e-01,\n",
       "          -4.1079e-01,  2.3757e-01, -8.8489e-03, -1.1169e-01, -2.4455e-01,\n",
       "          -3.5881e-01, -3.0782e-01,  7.9376e-03, -9.7143e-03, -2.4621e-01,\n",
       "          -2.7075e-01, -6.3403e-01, -1.5270e-01,  2.4267e-03,  3.7299e-01,\n",
       "          -2.5578e-01,  7.2947e-02,  1.4815e-01,  3.8708e-01, -2.5071e-01,\n",
       "           1.2053e-01,  8.2654e-01,  2.5076e-01, -8.6929e-02,  2.6227e-01,\n",
       "           1.0826e-01, -1.0061e-01, -8.2954e-02,  3.2549e-01,  3.7349e-01,\n",
       "          -1.2629e-01,  2.0674e-01, -4.6491e-01, -5.4386e-02,  3.6859e-02,\n",
       "          -1.0246e-01, -4.4074e-02, -1.8846e-01,  1.5918e-01,  1.1041e-01,\n",
       "          -1.9693e-01, -5.2231e-03,  4.5471e-01,  3.1962e-01,  1.8170e-01,\n",
       "           5.9720e-01,  1.4192e-01, -2.8801e-01, -8.5903e-02, -6.6822e-01,\n",
       "          -3.1334e-01, -5.4652e-01, -1.5787e-01, -5.2616e-01, -1.2153e-01,\n",
       "           4.6512e-02, -2.8512e-02,  2.9420e-01,  2.4360e-01,  3.4304e-01,\n",
       "          -4.7639e-01, -2.0093e-01, -1.3305e-01,  6.0361e-01, -1.0196e+00,\n",
       "           4.1653e-01, -1.2247e-01,  2.8018e-01,  7.7104e-02, -4.6254e-01,\n",
       "          -6.1674e-03, -1.1819e-01,  3.1368e-02, -4.2078e-01,  1.2199e-01,\n",
       "           3.7714e-01,  6.4042e-01, -1.4892e-01, -1.2380e-01,  4.0499e-01,\n",
       "           8.1172e-02, -2.6108e-01,  1.2353e+00, -4.2085e-01,  5.3401e-02,\n",
       "           4.3806e-01,  4.9905e-03,  1.5966e-01, -3.2628e-01, -2.0714e-01,\n",
       "          -6.9745e-02, -4.4324e-01, -1.7310e-01, -3.8416e-01,  5.3730e-01,\n",
       "           6.0244e-01, -2.2953e-02,  4.6874e-01, -3.8681e-01, -3.0356e-01,\n",
       "          -1.1778e-01,  7.9024e-02,  2.8313e-01,  1.9607e-01, -4.4079e-01,\n",
       "          -5.0245e-01,  2.8943e-01,  6.6221e-02, -2.2890e-01, -2.7951e-02,\n",
       "           1.0163e-01,  1.3791e-01, -7.2388e-03,  5.5484e-02, -2.1756e-01,\n",
       "          -2.1938e-02, -1.1624e-01,  2.4343e-01, -3.7118e-01,  1.5015e+00,\n",
       "           1.8739e-01,  5.5147e-01, -8.2221e-01,  2.0071e-01,  3.8490e-01,\n",
       "           1.8798e-01,  4.2493e-01, -7.1431e-01,  4.6347e-01, -1.6886e-01,\n",
       "          -4.3038e-01, -7.4773e-02, -7.6901e-02,  1.0490e-02,  3.7274e-01,\n",
       "           8.7618e-03, -1.5517e-01,  2.8306e-01, -5.0051e-01, -1.5680e-01,\n",
       "          -6.4817e-01, -1.5499e-01,  1.9880e-01, -7.8619e-01, -2.3470e-01,\n",
       "          -1.2395e-01,  3.5519e-02, -2.5137e-02,  3.5310e-01,  2.9772e-01,\n",
       "          -2.3087e-01, -1.4747e-01,  3.7306e-02,  9.5959e-02,  1.6445e-01,\n",
       "           1.2415e+00, -1.6394e-01, -1.7718e-01,  1.4408e-02, -2.3754e-01,\n",
       "          -2.0034e-01,  5.6214e-02,  1.2821e-01,  8.4153e-02,  2.8885e-01,\n",
       "          -2.6610e-01,  1.1050e-01,  5.5355e-02, -2.1661e-01,  3.7333e-01,\n",
       "          -3.2239e-01, -1.5702e-01,  4.9488e-01, -3.2092e-01, -2.4197e-01],\n",
       "         [-1.5311e-01, -5.0209e-01,  2.0982e-01,  4.7511e-01,  3.4444e-01,\n",
       "           9.6229e-02, -5.9028e-01,  4.3542e-01,  2.5019e-01, -2.3847e-01,\n",
       "           2.1133e-01,  4.8219e-01,  1.4911e-01, -7.4583e-01, -6.2543e-01,\n",
       "           1.3748e-01, -2.0089e-01,  1.5273e-01,  8.6992e-02, -4.2793e-01,\n",
       "           8.4686e-02,  4.9720e-02, -3.8321e-01,  1.4167e-01,  3.2294e-01,\n",
       "           1.7668e-01,  1.2038e-01, -1.8189e-01, -7.7948e-01, -1.8276e-01,\n",
       "           6.8458e-02, -5.1195e-01,  5.5865e-01,  1.0056e-01, -3.4005e-01,\n",
       "          -5.8983e-01, -6.6591e-01, -2.0263e-01,  2.5341e-01,  1.4496e-01,\n",
       "          -1.2165e-02, -2.7477e-01, -1.1882e-01,  4.8744e-01, -5.6713e-02,\n",
       "          -6.8190e-01,  3.7800e-01,  4.0983e-01, -3.5838e-01,  8.5574e-02,\n",
       "          -2.7683e-01,  3.8696e-01,  1.7341e-01,  8.0902e-01,  1.5079e-02,\n",
       "           2.1691e-01,  3.0654e-01, -4.2464e-01,  1.5920e-01, -1.2962e-01,\n",
       "          -5.2969e-01,  8.2508e-01,  2.9436e-01,  5.3452e-01,  3.5769e-01,\n",
       "           1.7151e-03, -1.1166e-01, -9.2438e-02,  1.0874e-01, -6.8890e-02,\n",
       "           1.8962e-01,  4.5510e-01, -1.4280e-01,  4.0787e-02, -7.0021e-01,\n",
       "          -6.1750e-01, -7.8251e-01, -6.7099e-01, -1.2818e-01, -5.5468e-01,\n",
       "           1.9069e-02,  1.2925e-02,  5.7014e-01, -4.2560e-01,  6.1435e-01,\n",
       "          -2.1803e-01,  6.1029e-02, -4.2508e-01,  5.4840e-01,  7.7505e-02,\n",
       "           1.9615e-01,  4.3940e-01,  2.4463e-01, -1.3368e-01,  1.5897e-01,\n",
       "           2.4203e-01, -1.5898e-01,  2.2029e-01,  4.5878e-02,  3.8181e-02,\n",
       "           5.3353e-03,  1.8207e-01,  2.6637e-01,  3.2717e-01,  2.4713e-01,\n",
       "           3.8327e-01,  1.3242e-01, -1.1376e-01, -2.7280e-01, -1.7620e-01,\n",
       "           4.7491e-01,  1.9214e-02,  1.5204e-01, -7.9199e-01,  4.1052e-01,\n",
       "          -2.5226e-01, -3.2518e-01,  6.8369e-01,  1.9546e-01,  2.8938e-01,\n",
       "           2.7821e-01,  1.9011e-01, -3.4625e-01, -2.6921e-01, -5.1182e-01,\n",
       "           5.5938e-01,  5.0170e-01,  7.4841e-01,  7.4279e-02, -1.3319e-02,\n",
       "          -1.1595e-01,  2.9334e-01,  4.3502e-01,  1.8229e-01, -1.2449e-01,\n",
       "           4.2696e-02,  1.0562e-01, -2.0766e-01,  1.8053e-01, -2.7543e-01,\n",
       "          -6.7060e-02, -1.5169e-01, -4.4741e-02,  3.4322e-03,  3.1621e-01,\n",
       "           5.3988e-02,  1.7386e-01, -1.3289e-01, -4.9630e-01,  2.0130e-01,\n",
       "           2.9566e-01, -8.0573e-02, -7.3843e-01,  3.8454e-01, -6.0239e-01,\n",
       "          -6.3357e-02, -5.5338e-01,  5.7844e-01,  1.5194e-01,  2.2057e-01,\n",
       "           8.0325e-01, -4.4244e-01, -3.2710e-01, -1.3126e-01, -1.1400e-01,\n",
       "          -5.3794e-01,  3.3454e-01, -6.4584e-01,  1.1926e-01, -3.6388e-01,\n",
       "           2.4141e-01,  6.8766e-02, -4.7638e-01, -1.8679e-02, -5.3164e-01,\n",
       "          -2.3459e-01, -2.6277e-02, -4.1864e-01, -2.8820e-01,  2.3468e-01,\n",
       "           1.2334e-01,  1.2858e-01,  1.5485e-01, -7.9919e-02,  3.4893e-02,\n",
       "           9.4341e-02, -1.6583e-01, -1.4310e-01,  1.9510e-01,  9.6792e-02,\n",
       "          -3.4397e-01, -2.0336e-02, -5.3379e-01, -1.2229e-01,  5.6093e-01,\n",
       "          -2.4048e-01,  3.4852e-01,  4.4030e-01,  5.1450e-02,  1.4510e-01]],\n",
       "        device='cuda:1'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text_transform = lambda x: [global_vectors.get_vecs_by_tokens('<BOS>')] + [global_vectors.get_vecs_by_tokens(token) for token in tokenizer(x)] + [global_vectors.get_vecs_by_tokens('<EOS>')]\n",
    "\n",
    "#t1 = text_transform(\"how are you?\")\n",
    " \n",
    "glove_embedding_tensor.shape,glove_embedding_tensor[1232:1234,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "text_transform = lambda x: [vocab['<BOS>']] + [vocab[token] for token in tokenizer(x)] + [vocab['<EOS>']]\n",
    "label_transform = lambda x: 1 if x == 'pos' else 0\n",
    "    \n",
    "def collate_batch(batch):\n",
    "   label_list, text_list = [], []\n",
    "   for (_label, _text) in batch: # each represents one text\n",
    "        label_list.append(label_transform(_label))\n",
    "        processed_text = torch.tensor(text_transform(_text))\n",
    "        text_list.append(processed_text)\n",
    "   return torch.tensor(label_list, dtype=torch.long).to(device), pad_sequence(text_list,  padding_value=1.0).to(device) # not using batch_first=True,\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EMy__zqIPbll"
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True , \n",
    "                              collate_fn=collate_batch)\n",
    " \n",
    "                  # collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_data, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  shuffle=True, \n",
    "                  collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  shuffle=True, \n",
    "                  collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EWQrfaT46CxW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    4, 22276,     4,  ...,   290,  1732,  1404],\n",
       "         [  409, 20475,  2989,  ...,    58,    41,  1405],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:1'),\n",
       " tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "         0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], device='cuda:1'),\n",
       " 1042,\n",
       " 64,\n",
       " torch.Size([1042, 64]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlabel, trainfeature = next(iter(train_dataloader)) \n",
    "trainfeature,trainlabel, len(trainfeature), len(trainlabel), trainfeature.shape, # len is by row\n",
    "\n",
    "\n",
    "# 1182 is the longest length of the batch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnqlCW9arhLP"
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YcA1qdwD6CxY"
   },
   "outputs": [],
   "source": [
    " # https://www.geeksforgeeks.org/pimport  \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_dim, \n",
    "                 output_dim, \n",
    "                 pad_idx):\n",
    "        super().__init__()\n",
    "        # change to pretrained embedding \n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            vocab_size, \n",
    "            embedding_dim, \n",
    "            padding_idx=pad_idx)\n",
    "\n",
    "        self.fc = torch.nn.Linear(embedding_dim, \n",
    "                            output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        embedded = self.embedding(text) \n",
    "        # text is the numeric indices of words \n",
    "        # the indices are be based on the pretrained dictionary \n",
    "\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        pooled = F.avg_pool2d(\n",
    "            embedded, \n",
    "            (embedded.shape[1], 1)).squeeze(1) \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "w43pDDgT6CxY"
   },
   "outputs": [],
   "source": [
    "model = FastText(\n",
    "            vocab_size = len(vocab), \n",
    "            embedding_dim = embed_len, \n",
    "            output_dim = 1, \n",
    "            pad_idx = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRrHD3Ss6Cxb"
   },
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding = torch.nn.Embedding.from_pretrained(glove_embedding_tensor,freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7lpQKr4u-qjA"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211542,
     "status": "ok",
     "timestamp": 1615844247885,
     "user": {
      "displayName": "Joe Papa",
      "photoUrl": "",
      "userId": "00487850786587503652"
     },
     "user_tz": 240
    },
    "id": "B7hBXR41-4HE",
    "outputId": "8dbc4e39-8490-499d-fa90-654d81f60e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train: Loss: 0.6894 Acc: 0.5889\n",
      "Epoch 0 Valid: Loss: 0.6850 Acc: 0.6302\n",
      "Epoch 1 Train: Loss: 0.6810 Acc: 0.6505\n",
      "Epoch 1 Valid: Loss: 0.6779 Acc: 0.6241\n",
      "Epoch 2 Train: Loss: 0.6734 Acc: 0.6620\n",
      "Epoch 2 Valid: Loss: 0.6708 Acc: 0.6701\n",
      "Epoch 3 Train: Loss: 0.6662 Acc: 0.6777\n",
      "Epoch 3 Valid: Loss: 0.6639 Acc: 0.6755\n",
      "Epoch 4 Train: Loss: 0.6605 Acc: 0.6880\n",
      "Epoch 4 Valid: Loss: 0.6587 Acc: 0.6758\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  \n",
    "  model.train()\n",
    "  for label, text in train_dataloader:\n",
    "      #print(label.dtype)\n",
    "      #print(text)\n",
    "      optimizer.zero_grad()\n",
    "      predictions = model(text).squeeze(1)\n",
    "      #print(predictions.dtype)\n",
    "      loss = criterion(predictions, label.float())\n",
    "      \n",
    "      rounded_preds = torch.round(\n",
    "          torch.sigmoid(predictions))\n",
    "      correct = \\\n",
    "        (rounded_preds == label).float()\n",
    "      acc = correct.sum() / len(correct)\n",
    "      \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "\n",
    "  print(\"Epoch %d Train: Loss: %.4f Acc: %.4f\" %\n",
    "          (epoch,\n",
    "          epoch_loss / len(train_dataloader), \n",
    "          epoch_acc / len(train_dataloader)))\n",
    "\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for label, text in valid_dataloader:\n",
    "      predictions = model(text).squeeze(1)\n",
    "      loss = criterion(predictions, label.float())\n",
    "      \n",
    "      rounded_preds = torch.round(\n",
    "          torch.sigmoid(predictions))\n",
    "      correct = \\\n",
    "        (rounded_preds == label).float()\n",
    "      acc = correct.sum() / len(correct)\n",
    "      \n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "\n",
    "  print(\"Epoch %d Valid: Loss: %.4f Acc: %.4f\" %\n",
    "          (epoch,\n",
    "          epoch_loss / len(valid_dataloader), \n",
    "          epoch_acc / len(valid_dataloader)))\n",
    "  \n",
    "# out: (your results may vary)\n",
    "# Epoch 0 Train: Loss: 0.6523 Acc: 0.7165\n",
    "# Epoch 0 Valid: Loss: 0.5259 Acc: 0.7474\n",
    "# Epoch 1 Train: Loss: 0.5935 Acc: 0.7765\n",
    "# Epoch 1 Valid: Loss: 0.4571 Acc: 0.7933\n",
    "# Epoch 2 Train: Loss: 0.5230 Acc: 0.8257\n",
    "# Epoch 2 Valid: Loss: 0.4103 Acc: 0.8245\n",
    "# Epoch 3 Train: Loss: 0.4559 Acc: 0.8598\n",
    "# Epoch 3 Valid: Loss: 0.3828 Acc: 0.8549\n",
    "# Epoch 4 Train: Loss: 0.4004 Acc: 0.8813\n",
    "# Epoch 4 Valid: Loss: 0.3781 Acc: 0.8675"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfBcC4qWDkcS"
   },
   "source": [
    "# Testing & Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41614,
     "status": "ok",
     "timestamp": 1615844337404,
     "user": {
      "displayName": "Joe Papa",
      "photoUrl": "",
      "userId": "00487850786587503652"
     },
     "user_tz": 240
    },
    "id": "WdDAlQlaDP0-",
    "outputId": "5a523532-a9b5-4cc4-8803-84c9ad121358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.6590 Acc: 0.6740\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_acc = 0\n",
    "model.eval() # <1>\n",
    "with torch.no_grad(): # <1>\n",
    "  for label, text in test_dataloader:\n",
    "    predictions = model(text).squeeze(1)\n",
    "    loss = criterion(predictions, label.float())\n",
    "    \n",
    "    rounded_preds = torch.round(\n",
    "        torch.sigmoid(predictions))\n",
    "    correct = \\\n",
    "      (rounded_preds == label).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "\n",
    "    test_loss += loss.item()\n",
    "    test_acc += acc.item()\n",
    "\n",
    "print(\"Test: Loss: %.4f Acc: %.4f\" %\n",
    "        (test_loss / len(test_dataloader), \n",
    "        test_acc / len(test_dataloader)))\n",
    "# out: (your results will vary)\n",
    "#   Test: Loss: 0.3821 Acc: 0.8599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1615844842113,
     "user": {
      "displayName": "Joe Papa",
      "photoUrl": "",
      "userId": "00487850786587503652"
     },
     "user_tz": 240
    },
    "id": "yncFrpAcD2GY",
    "outputId": "fbd7ff12-c2ce-410c-e8d2-88dfdbb80487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007512994576245546\n",
      "0.03589097410440445\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] \n",
    "      for token in tokenizer(x)]\n",
    "\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    text = torch.tensor(text_pipeline(sentence)).unsqueeze(1).to(device)\n",
    "    prediction = torch.sigmoid(model(text))\n",
    "    return prediction.item()\n",
    "\n",
    "sentiment = predict_sentiment(model, \n",
    "                  \"Don't waste your time\")\n",
    "print(sentiment)\n",
    "# out: 4.763594888613835e-34\n",
    "\n",
    "sentiment = predict_sentiment(model, \n",
    "                  \"You gotta see this movie!\")\n",
    "print(sentiment)\n",
    "# out: 0.941755473613739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "adVgHt83EGbs"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fasttext-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pJ2CmUZq21-6"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM1Y66iHpZIpvg6TX6U00ZP",
   "collapsed_sections": [],
   "name": "04_02_Sentiment_Analysis_with_TorchText.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "8d1b3b63f0ab60c7236a713968b959123020c0d6fb9cdd1ffb50b409abe40ad8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
